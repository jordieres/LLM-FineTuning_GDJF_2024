{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb154716-9a01-4dab-a3d2-7080235e722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script para la extracción de frases y referencias de un PDF a un CSV\n",
    "# Versión 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702f6f0d-e2d1-4328-a44e-b199417789c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed XML file 1: 2406.04353v1.cermxml\n",
      "Processed XML file 2: 2209.04206v1.cermxml\n",
      "Processed XML file 3: 2009.09310v1.cermxml\n",
      "Processed XML file 4: 2402.03122v3.cermxml\n",
      "Processed XML file 5: 2106.11168v1.cermxml\n",
      "Processed XML file 6: 2111.13436v2.cermxml\n",
      "Processed XML file 7: 2407.08406v1.cermxml\n",
      "Processed XML file 8: 1909.10018v1.cermxml\n",
      "Processed XML file 9: 2406.09966v1.cermxml\n",
      "Processed XML file 10: 2009.12883v1.cermxml\n",
      "Processed XML file 11: 2402.00066v1.cermxml\n",
      "Processed XML file 12: 2111.06116v1.cermxml\n",
      "Processed XML file 13: 2201.10636v2.cermxml\n",
      "Processed XML file 14: 2302.03778v1.cermxml\n",
      "Processed XML file 15: 2301.07676v1.cermxml\n",
      "Processed XML file 16: 1909.07438v1.cermxml\n",
      "Processed XML file 17: 1911.03240v1.cermxml\n",
      "Processed XML file 18: 2110.10053v1.cermxml\n",
      "Processed XML file 19: 2004.07354v1.cermxml\n",
      "Processed XML file 20: 2111.05605v1.cermxml\n",
      "Processed XML file 21: 2406.04354v1.cermxml\n",
      "Processed XML file 22: 0911.1759v1.cermxml\n",
      "Processed XML file 23: 2002.08811v2.cermxml\n",
      "Processed XML file 24: 2211.10149v2.cermxml\n",
      "Processed XML file 25: 1209.1318v1.cermxml\n",
      "Processed XML file 26: 1703.08484v1.cermxml\n",
      "Processed XML file 27: 2311.15914v1.cermxml\n",
      "Processed XML file 28: 1203.3384v2.cermxml\n",
      "Processed XML file 29: 2208.12980v1.cermxml\n",
      "Processed XML file 30: 2101.08812v1.cermxml\n",
      "Processed XML file 31: 2301.09574v1.cermxml\n",
      "Processed XML file 32: 2204.10826v2.cermxml\n",
      "Processed XML file 33: 0703013v1.cermxml\n",
      "Processed XML file 34: 2401.04032v2.cermxml\n",
      "Processed XML file 35: 2201.06947v2.cermxml\n",
      "Processed XML file 36: 2305.10451v1.cermxml\n",
      "Processed XML file 37: 2209.01952v1.cermxml\n",
      "Processed XML file 38: 2203.11312v4.cermxml\n",
      "Processed XML file 39: 2201.08467v1.cermxml\n",
      "Processed XML file 40: 2204.04085v2.cermxml\n",
      "Processed XML file 41: 2310.05199v5.cermxml\n",
      "Processed XML file 42: 1612.03308v1.cermxml\n",
      "Processed XML file 43: 2007.14732v1.cermxml\n",
      "Processed XML file 44: 2312.16943v4.cermxml\n",
      "Processed XML file 45: 2404.02135v3.cermxml\n",
      "Processed XML file 46: 2002.04744v2.cermxml\n",
      "Processed XML file 47: 2401.18067v1.cermxml\n",
      "Processed XML file 48: 2011.00251v1.cermxml\n",
      "Processed XML file 49: 2211.05830v2.cermxml\n",
      "Processed XML file 50: 1705.01681v1.cermxml\n",
      "Processed XML file 51: 2311.11580v1.cermxml\n",
      "Processed XML file 52: 2207.04140v1.cermxml\n",
      "Processed XML file 53: 2007.07148v1.cermxml\n",
      "Processed XML file 54: 1911.04198v1.cermxml\n",
      "Processed XML file 55: 2307.06688v1.cermxml\n",
      "Processed XML file 56: 1812.00989v1.cermxml\n",
      "Processed XML file 57: 2208.14842v1.cermxml\n",
      "Processed XML file 58: 1911.10498v1.cermxml\n",
      "Processed XML file 59: 1810.02856v1.cermxml\n",
      "Processed XML file 60: 2403.07007v1.cermxml\n",
      "Processed XML file 61: 1204.0195v1.cermxml\n",
      "Processed XML file 62: 2203.00369v1.cermxml\n",
      "Processed XML file 63: 2310.12880v2.cermxml\n",
      "Processed XML file 64: 1603.00802v1.cermxml\n",
      "Processed XML file 65: 0804.2913v1.cermxml\n",
      "Processed XML file 66: 2402.03337v1.cermxml\n",
      "Processed XML file 67: 2212.04132v1.cermxml\n",
      "Processed XML file 68: 2208.10569v1.cermxml\n",
      "Processed XML file 69: 1508.00181v1.cermxml\n",
      "Extraction and CSV creation completed successfully for all XML files.\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Función que extrae título y año dado un número de referencia específico, útil para\n",
    "# extraer DOIs debido a que son los inputs de la API:\n",
    "def format_reference(ref):\n",
    "    # Initial default values\n",
    "    title = ''\n",
    "    year = ''\n",
    "    \n",
    "    # Extract title from article-title if available\n",
    "    article_title = ref.xpath('.//article-title/text()')\n",
    "    source_text = ref.xpath('.//source/text()')\n",
    "    \n",
    "    if article_title:\n",
    "        title = article_title[0]\n",
    "        year = ref.xpath('.//year/text()')[0] if ref.xpath('.//year/text()') else ''\n",
    "    elif source_text:\n",
    "        title = source_text[0]\n",
    "        year = ref.xpath('.//year/text()')[0] if ref.xpath('.//year/text()') else ''\n",
    "    \n",
    "    return title, year\n",
    "\n",
    "\n",
    "# Función que \"normaliza\" los espacios entre palabras (si hay más de 1 espacio,\n",
    "# si hay un salto de línea, etc):\n",
    "def normalize_whitespace(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "\n",
    "# Función que se encarga de separar las distintas oraciones. También se encarga de\n",
    "# interpretar cuando una abreviación no constituye el inicio de una oración nueva\n",
    "# (debido a puntos que pueda contener en su interior), cuando signos de interrogación\n",
    "# o exclamación marcan el final de una oración, etc.:\n",
    "def split_sentences_with_tags(paragraph_text):\n",
    "    # Dictionary of abbreviations to protect\n",
    "    abbreviations = {\n",
    "        'e.g. ': 'EG_PLACEHOLDER ',\n",
    "        'e.g.': 'EG_PLACEHOLDER',\n",
    "        'et al. ': 'ETAL_PLACEHOLDER ',\n",
    "        'et al.': 'ETAL_PLACEHOLDER',\n",
    "        'i.e. ': 'IE_PLACEHOLDER ',\n",
    "        'i.e.': 'IE_PLACEHOLDER',\n",
    "        'fig.': 'FIG_PLACEHOLDER',\n",
    "        'fig. ': 'FIG2_PLACEHOLDER',\n",
    "        'vs.': 'VS_PLACEHOLDER',\n",
    "        'p. ': 'P_PLACEHOLDER',\n",
    "    }\n",
    "    \n",
    "    # Temporarily replace abbreviations with placeholders\n",
    "    for abbr, placeholder in abbreviations.items():\n",
    "        paragraph_text = re.sub(f'\\\\b{abbr}\\\\b', placeholder, paragraph_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Split sentences on periods, exclamations, or question marks that are not followed by a closing parenthesis unless it's the end of the text\n",
    "    sentences = re.split(r'(?<=[.!?])(?!\\s*[\\)\\[])\\s+', paragraph_text)\n",
    "    \n",
    "    # Restore the original abbreviations\n",
    "    for abbr, placeholder in abbreviations.items():\n",
    "        sentences = [sentence.replace(placeholder, abbr) for sentence in sentences]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "# Función que se encarga de procesar las separaciónes que no cumplan ciertos criterios:\n",
    "def split_sentences(sentences):\n",
    "    i = 0\n",
    "    while i < len(sentences) - 1:\n",
    "        # Check if the sentence ends with \"e.g.\", \"et al.\" or similar and the next does not start properly as a new sentence\n",
    "        if any(sentences[i].endswith(x) for x in ['e.g.', 'et al.', 'i.e.', 'fig.', 'vs.']) and \\\n",
    "           (sentences[i+1][0].islower() or sentences[i+1][0].isdigit() or sentences[i+1].startswith('(')):\n",
    "            sentences[i] = sentences[i] + ' ' + sentences[i+1]\n",
    "            del sentences[i+1]\n",
    "        else:\n",
    "            i += 1\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# Función que se encarga de ir oración a oración asociando las oraciones con referencias\n",
    "# a su respectiva referencia usando las funciones definidas anteriormente\n",
    "def extract_sentences_with_references_correctly(root, references):\n",
    "    context_with_refs = []\n",
    "    for body in root.xpath('.//body'):\n",
    "        for p in body.xpath('.//p'):\n",
    "            paragraph_html = etree.tostring(p, method='html', encoding='unicode')\n",
    "            sentences = split_sentences_with_tags(paragraph_html)\n",
    "            sentences = split_sentences(sentences)\n",
    "\n",
    "            for sentence_html in sentences:\n",
    "                if has_reference(sentence_html):\n",
    "                    sentence_text = etree.fromstring(sentence_html, parser=etree.HTMLParser()).xpath('string()')\n",
    "                    sentence_text = normalize_whitespace(sentence_text).strip()\n",
    "\n",
    "                    sentence_xrefs = etree.fromstring(sentence_html, parser=etree.HTMLParser()).xpath('.//xref[@ref-type=\"bibr\"]')\n",
    "                    titles = []\n",
    "                    years = []\n",
    "                    for xref in sentence_xrefs:\n",
    "                        rid = xref.get('rid')\n",
    "                        if rid:\n",
    "                            ref_ids = rid.split()\n",
    "                            for ref_id in ref_ids:\n",
    "                                reference_xml = root.xpath(f'.//ref[@id=\"{ref_id}\"]')[0]\n",
    "                                title, year = format_reference(reference_xml)\n",
    "                                if (title, year) not in zip(titles, years):\n",
    "                                    titles.append(title)\n",
    "                                    years.append(year)\n",
    "                    titles_str = '\\n'.join(titles) if titles else \"No title found\"\n",
    "                    years_str = '\\n'.join(years) if years else \"No year found\"\n",
    "                else:\n",
    "                    sentence_text = etree.fromstring(f'<div>{sentence_html}</div>', parser=etree.HTMLParser()).xpath('string()')\n",
    "                    sentence_text = normalize_whitespace(sentence_text).strip()\n",
    "                    titles_str = \"\"\n",
    "                    years_str = \"\"\n",
    "                \n",
    "                context_with_refs.append((sentence_text, titles_str, years_str))\n",
    "                \n",
    "    return context_with_refs\n",
    "\n",
    "# Función que busca las etiquetas específicas del estándar NLM JATS\n",
    "def has_reference(sentence_xml):\n",
    "    # Pattern to detect <xref ref-type=\"bibr\" ...> tags\n",
    "    xref_pattern = re.compile(r'<xref ref-type=\"bibr\"')\n",
    "    # Search for the pattern in the sentence XML content\n",
    "    return bool(xref_pattern.search(sentence_xml))\n",
    "\n",
    "\n",
    "# Directorio que contiene los XMLs\n",
    "xml_directory = 'XMLs'\n",
    "\n",
    "\n",
    "# Contador del número de archivos XML procesador\n",
    "file_count = 0\n",
    "\n",
    "\n",
    "# Iteración para todos los XMLs en el directorio especificado\n",
    "for xml_file in os.listdir(xml_directory):\n",
    "    if xml_file.endswith('.cermxml'):\n",
    "        file_path = os.path.join(xml_directory, xml_file)\n",
    "        \n",
    "        # Load and parse the XML file\n",
    "        tree = etree.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Creating a dictionary of references\n",
    "        references = {ref.get('id'): format_reference(ref) for ref in root.xpath('.//ref-list/ref')}\n",
    "\n",
    "        # Extract sentences and references\n",
    "        sentences_with_references = extract_sentences_with_references_correctly(root, references)\n",
    "\n",
    "        # Define the output CSV file name based on the input XML file name\n",
    "        csv_file_name = os.path.splitext(xml_file)[0] + '_output.csv'\n",
    "        csv_file_path = os.path.join(xml_directory, csv_file_name)\n",
    "\n",
    "        # Write the sentences and their references to a CSV file\n",
    "        with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Context\", \"Title\", \"Year\"])  # Adjusted header\n",
    "            for context, titles, years in sentences_with_references:\n",
    "                writer.writerow([context, titles, years])\n",
    "        \n",
    "        # Increment the file counter and print the number of processed files\n",
    "        file_count += 1\n",
    "        print(f\"Processed XML file {file_count}: {xml_file}\")\n",
    "\n",
    "print(\"Extraction and CSV creation completed successfully for all XML files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6a2f4-db11-48a0-9ef4-f2148c28ef89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
